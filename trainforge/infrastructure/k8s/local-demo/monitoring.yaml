# TrainForge Monitoring Stack for K8s
# Provides real-time monitoring of distributed training

apiVersion: apps/v1
kind: Deployment
metadata:
  name: trainforge-monitor
  namespace: default
  labels:
    app: trainforge-monitor
    component: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trainforge-monitor
  template:
    metadata:
      labels:
        app: trainforge-monitor
        component: monitoring
    spec:
      containers:
      - name: resource-monitor
        image: python:3.9-slim
        imagePullPolicy: IfNotPresent
        
        resources:
          requests:
            cpu: "0.1"
            memory: "128Mi"
          limits:
            cpu: "0.3"
            memory: "256Mi"
        
        env:
        - name: MONITOR_INTERVAL
          value: "5"
        - name: EXPORT_METRICS
          value: "true"
        
        command: ["/bin/bash"]
        args:
        - -c
        - |
          pip install kubernetes psutil requests
          python -c "
          import time
          import json
          import os
          from datetime import datetime
          from kubernetes import client, config
          import psutil
          
          print('TrainForge Resource Monitor started')
          
          # Load K8s config
          try:
              config.load_incluster_config()
          except:
              config.load_kube_config()
          
          v1 = client.CoreV1Api()
          metrics_api = client.CustomObjectsApi()
          
          def collect_node_metrics():
              '''Collect node-level resource metrics'''
              try:
                  nodes = v1.list_node()
                  node_metrics = []
                  
                  for node in nodes.items:
                      # Get node status
                      conditions = {c.type: c.status for c in node.status.conditions}
                      
                      # Calculate resource allocation
                      allocatable = node.status.allocatable
                      capacity = node.status.capacity
                      
                      metric = {
                          'node_name': node.metadata.name,
                          'ready': conditions.get('Ready', 'Unknown'),
                          'cpu_capacity': capacity.get('cpu', '0'),
                          'memory_capacity': capacity.get('memory', '0'),
                          'cpu_allocatable': allocatable.get('cpu', '0'),
                          'memory_allocatable': allocatable.get('memory', '0'),
                          'timestamp': datetime.now().isoformat()
                      }
                      node_metrics.append(metric)
                  
                  return node_metrics
              except Exception as e:
                  print(f'Error collecting node metrics: {e}')
                  return []
          
          def collect_pod_metrics():
              '''Collect pod-level resource metrics'''
              try:
                  pods = v1.list_namespaced_pod(
                      namespace='default',
                      label_selector='app=trainforge-worker'
                  )
                  
                  pod_metrics = []
                  for pod in pods.items:
                      # Get pod resource requests/limits
                      container = pod.spec.containers[0]
                      requests = container.resources.requests or {}
                      limits = container.resources.limits or {}
                      
                      metric = {
                          'pod_name': pod.metadata.name,
                          'namespace': pod.metadata.namespace,
                          'phase': pod.status.phase,
                          'node_name': pod.spec.node_name,
                          'cpu_request': requests.get('cpu', '0'),
                          'memory_request': requests.get('memory', '0'),
                          'cpu_limit': limits.get('cpu', '0'),
                          'memory_limit': limits.get('memory', '0'),
                          'restart_count': sum(c.restart_count for c in pod.status.container_statuses or []),
                          'timestamp': datetime.now().isoformat()
                      }
                      
                      # Add phase-specific info
                      if pod.status.phase == 'Running':
                          metric['started_at'] = pod.status.start_time.isoformat() if pod.status.start_time else None
                      
                      pod_metrics.append(metric)
                  
                  return pod_metrics
              except Exception as e:
                  print(f'Error collecting pod metrics: {e}')
                  return []
          
          def calculate_cluster_utilization(node_metrics, pod_metrics):
              '''Calculate overall cluster resource utilization'''
              try:
                  # Count running pods
                  running_pods = [p for p in pod_metrics if p['phase'] == 'Running']
                  
                  # Calculate total requested resources
                  total_cpu_requested = 0
                  total_memory_requested = 0
                  
                  for pod in running_pods:
                      # Parse CPU (convert from string like '0.5' or '500m')
                      cpu_req = pod['cpu_request']
                      if cpu_req.endswith('m'):
                          cpu_val = float(cpu_req[:-1]) / 1000
                      else:
                          cpu_val = float(cpu_req) if cpu_req != '0' else 0
                      total_cpu_requested += cpu_val
                      
                      # Parse Memory (convert from string like '512Mi')
                      mem_req = pod['memory_request']
                      if mem_req.endswith('Mi'):
                          mem_val = float(mem_req[:-2])
                      elif mem_req.endswith('Gi'):
                          mem_val = float(mem_req[:-2]) * 1024
                      else:
                          mem_val = 0
                      total_memory_requested += mem_val
                  
                  utilization = {
                      'timestamp': datetime.now().isoformat(),
                      'total_nodes': len(node_metrics),
                      'total_pods': len(pod_metrics),
                      'running_pods': len(running_pods),
                      'total_cpu_requested': total_cpu_requested,
                      'total_memory_requested_mi': total_memory_requested,
                      'average_pod_cpu': total_cpu_requested / len(running_pods) if running_pods else 0,
                      'average_pod_memory': total_memory_requested / len(running_pods) if running_pods else 0,
                      'cluster_health': 'healthy' if len(running_pods) > 0 else 'degraded'
                  }
                  
                  return utilization
              except Exception as e:
                  print(f'Error calculating utilization: {e}')
                  return {}
          
          # Main monitoring loop
          iteration = 0
          while True:
              try:
                  iteration += 1
                  print(f'\\n--- Monitor Iteration {iteration} ---')
                  
                  # Collect metrics
                  node_metrics = collect_node_metrics()
                  pod_metrics = collect_pod_metrics()
                  utilization = calculate_cluster_utilization(node_metrics, pod_metrics)
                  
                  # Report summary
                  print(f'Cluster Status:')
                  print(f'  Nodes: {len(node_metrics)}')
                  print(f'  Total Pods: {len(pod_metrics)}')
                  print(f'  Running Pods: {utilization.get(\"running_pods\", 0)}')
                  print(f'  CPU Requested: {utilization.get(\"total_cpu_requested\", 0):.2f} cores')
                  print(f'  Memory Requested: {utilization.get(\"total_memory_requested_mi\", 0):.0f}Mi')
                  
                  # Detailed pod status
                  for pod in pod_metrics:
                      status_icon = 'ðŸŸ¢' if pod['phase'] == 'Running' else 'ðŸŸ¡' if pod['phase'] == 'Pending' else 'ðŸ”´'
                      print(f'  {status_icon} {pod[\"pod_name\"]}: {pod[\"phase\"]} on {pod[\"node_name\"]}')
                  
                  # Export metrics (simulate sending to monitoring system)
                  if os.getenv('EXPORT_METRICS') == 'true':
                      metrics_export = {
                          'cluster_metrics': utilization,
                          'node_metrics': node_metrics,
                          'pod_metrics': pod_metrics
                      }
                      # In real system, this would send to Prometheus/Grafana
                      print(f'Exported metrics: {len(pod_metrics)} pods, {len(node_metrics)} nodes')
                  
                  # Wait for next iteration
                  interval = int(os.getenv('MONITOR_INTERVAL', '10'))
                  time.sleep(interval)
                  
              except Exception as e:
                  print(f'Monitor error: {e}')
                  time.sleep(10)
          "
        
        ports:
        - containerPort: 9090
          name: metrics
        
        livenessProbe:
          exec:
            command:
            - python
            - -c
            - "print('Monitor healthy')"
          initialDelaySeconds: 15
          periodSeconds: 30

---
# Service for monitoring
apiVersion: v1
kind: Service
metadata:
  name: trainforge-monitor-service
  labels:
    app: trainforge-monitor
spec:
  selector:
    app: trainforge-monitor
  ports:
  - port: 9090
    targetPort: 9090
    name: metrics
  type: ClusterIP

---
# ConfigMap for monitoring configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: trainforge-monitor-config
data:
  config.yaml: |
    monitoring:
      interval_seconds: 5
      export_enabled: true
      metrics:
        - cpu_utilization
        - memory_utilization
        - pod_count
        - node_health
    
    alerts:
      high_cpu_threshold: 80
      high_memory_threshold: 85
      pod_failure_threshold: 2
    
    dashboard:
      refresh_interval: 10
      charts:
        - resource_utilization
        - pod_status
        - training_progress