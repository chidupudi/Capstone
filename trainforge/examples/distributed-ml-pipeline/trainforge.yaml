# TrainForge Configuration for Distributed ML Pipeline
# Real-world machine learning pipeline with distributed processing

project:
  name: "distributed-ml-pipeline"
  description: "Complete ML pipeline: data generation → feature extraction → training → evaluation"
  version: "1.0"

# Training configuration
training:
  script: "train.py"
  type: "distributed"
  framework: "scikit-learn"

# Resource requirements
resources:
  gpu: 0
  cpu: 8
  memory: "6Gi"

# Pipeline stages
pipeline:
  stages:
    - name: "data_generation"
      description: "Generate synthetic dataset with distributed processing"
      workers: 8
      
    - name: "feature_extraction"
      description: "Extract features using parallel processing"
      workers: 8
      
    - name: "model_training"
      description: "Train ML model with distributed batch processing"
      workers: 4
      
    - name: "model_evaluation"
      description: "Evaluate model performance in parallel"
      workers: 4

# Performance monitoring
monitoring:
  enabled: true
  metrics:
    - "cpu_utilization"
    - "memory_usage"
    - "processing_throughput"
    - "stage_duration"
    - "worker_efficiency"

# Output artifacts
artifacts:
  - name: "pipeline_statistics"
    type: "json"
    path: "ml_pipeline_statistics.json"
    description: "Complete pipeline performance metrics"